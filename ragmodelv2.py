# Import necessary libraries
import json
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import ollama
import glob
import os
import random

# Step 1: Load JSON Data

def load_json_data(folder_path):
    """
    Load data from multiple JSON files in a specified folder.
    :param folder_path: Path to the folder containing JSON files.
    :return: List of text paragraphs.
    """
    data = []
    json_paths = glob.glob(os.path.join(folder_path, "*.json"))
    for json_path in json_paths:
        with open(json_path, 'r', encoding='utf-8') as json_file:
            json_data = json.load(json_file)
            data.extend([entry['text'] for entry in json_data])
    return data

# Load the coursework data from JSON files in the specified folder
folder_path = "your_folder_path_here"
data = load_json_data(folder_path)

# Step 2: Generate Embeddings Using SentenceTransformer

# Load a pre-trained model from SentenceTransformers
model = SentenceTransformer('all-MiniLM-L6-v2')

# Generate embeddings for each paragraph
embeddings = model.encode(data, convert_to_tensor=False, show_progress_bar=True)
embeddings = np.array(embeddings)

# Step 3: Create and Index the FAISS Vector Store

def create_faiss_index(embeddings):
    """
    Create a FAISS index for the given embeddings.
    :param embeddings: Embeddings of the text data.
    :return: FAISS index.
    """
    # Create a FAISS index with the dimensions of the embedding
    d = embeddings.shape[1]
    index = faiss.IndexFlatL2(d)
    
    # Add embeddings to the index
    index.add(embeddings)
    return index

# Create the FAISS index
index = create_faiss_index(embeddings)

# Step 4: Implement a Function for Retrieval and Ollama Query

def retrieve_and_query_ollama(query, index, data, model_name="llama2-base"):
    """
    Retrieve relevant content from indexed data and use Ollama to generate a one-word response.
    :param query: The query string.
    :param index: The FAISS index.
    :param data: Original text data.
    :param model_name: Name of the Ollama model to use.
    :return: One-word response generated by Ollama.
    """
    # Encode the query
    query_embedding = model.encode([query], convert_to_tensor=False)
    query_embedding = np.array(query_embedding)
    
    # Search the FAISS index for the closest matches
    k = 5  # Number of matches to retrieve
    distances, indices = index.search(query_embedding, k)
    
    # Retrieve the relevant paragraphs
    retrieved_paragraphs = [data[idx] for idx in indices[0]]
    context = "\n".join(retrieved_paragraphs)
    
    # Use Ollama to generate a response
    ollama_response = ollama.generate(
        model=model_name,
        prompt=f"Context:\n{context}\n\nQuestion: {query}\nAnswer (one word):"
    )
    
    # Extract the first word from the response as the final answer
    one_word_response = ollama_response.split()[0] if ollama_response else ""
    
    return one_word_response

# Step 5: Define the Reward Function for Reinforcement Learning

def reward_function(model_response, correct_answer):
    """
    Reward function to evaluate the model's response.
    :param model_response: The response generated by the model.
    :param correct_answer: The correct answer from the quiz data.
    :return: Reward value (+1 for correct, -1 for incorrect).
    """
    return 1 if correct_answer.lower() == model_response.lower() else -1

# Step 6: Reinforcement Learning Training Loop

def rl_training_loop(quiz_data, index, data, episodes=100):
    """
    Train the model using a reinforcement learning loop.
    :param quiz_data: List of dictionaries with 'question' and 'correct_answer'.
    :param index: FAISS index for retrieving context.
    :param data: Original text data.
    :param episodes: Number of episodes to train for.
    """
    total_reward = 0

    for episode in range(episodes):
        # Sample a random quiz question
        quiz_item = random.choice(quiz_data)
        question = quiz_item['question']
        correct_answer = quiz_item['correct_answer']

        # Retrieve and generate response
        model_response = retrieve_and_query_ollama(question, index, data)

        # Calculate reward
        reward = reward_function(model_response, correct_answer)
        total_reward += reward

        # Print episode info
        print(f"Episode {episode + 1}/{episodes}")
        print(f"Question: {question}")
        print(f"Model Response: {model_response}")
        print(f"Correct Answer: {correct_answer}")
        print(f"Reward: {reward}\n")

    print(f"Total reward after {episodes} episodes: {total_reward}")

# Step 7: Example Quiz Data and Start Training

quiz_data = [
    {"question": "What are the fundamentals of requirements gathering?", "correct_answer": "elicitation"},
    {"question": "Define the purpose of a business model canvas.", "correct_answer": "strategy"},
    # Add more quiz questions as needed
]

# Start Reinforcement Learning Training
rl_training_loop(quiz_data, index, data)